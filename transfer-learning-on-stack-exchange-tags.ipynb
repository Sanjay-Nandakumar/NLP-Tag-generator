{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e225d2c-5d32-0e56-e5ae-2414410235d7"
   },
   "source": [
    "Transfer Learning on Stack Exchange Tags\n",
    "========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ad7c0f0d-0068-1fd7-7619-ca1bed95e17f"
   },
   "source": [
    "Step 1: Explore Data\n",
    "--------------------\n",
    "\n",
    "Before we can start training a ML model, we need to understand the data we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "ecc07329-c486-779e-41ca-4d39475b1c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Biology: 13196 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the criticality of the ribosome bindin...</td>\n",
       "      <td>&lt;p&gt;In prokaryotic translation, how critical fo...</td>\n",
       "      <td>ribosome binding-sites translation synthetic-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How is RNAse contamination in RNA based experi...</td>\n",
       "      <td>&lt;p&gt;Does anyone have any suggestions to prevent...</td>\n",
       "      <td>rna biochemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Are lymphocyte sizes clustered in two groups?</td>\n",
       "      <td>&lt;p&gt;Tortora writes in &lt;em&gt;Principles of Anatomy...</td>\n",
       "      <td>immunology cell-biology hematology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How long does antibiotic-dosed LB maintain goo...</td>\n",
       "      <td>&lt;p&gt;Various people in our lab will prepare a li...</td>\n",
       "      <td>cell-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Is exon order always preserved in splicing?</td>\n",
       "      <td>&lt;p&gt;Are there any cases in which the splicing m...</td>\n",
       "      <td>splicing mrna spliceosome introns exons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is the criticality of the ribosome bindin...   \n",
       "1   2  How is RNAse contamination in RNA based experi...   \n",
       "2   3      Are lymphocyte sizes clustered in two groups?   \n",
       "3   4  How long does antibiotic-dosed LB maintain goo...   \n",
       "4   5        Is exon order always preserved in splicing?   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>In prokaryotic translation, how critical fo...   \n",
       "1  <p>Does anyone have any suggestions to prevent...   \n",
       "2  <p>Tortora writes in <em>Principles of Anatomy...   \n",
       "3  <p>Various people in our lab will prepare a li...   \n",
       "4  <p>Are there any cases in which the splicing m...   \n",
       "\n",
       "                                                tags  \n",
       "0  ribosome binding-sites translation synthetic-b...  \n",
       "1                                   rna biochemistry  \n",
       "2                 immunology cell-biology hematology  \n",
       "3                                       cell-culture  \n",
       "4            splicing mrna spliceosome introns exons  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cooking: 15404 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How can I get chewy chocolate chip cookies?</td>\n",
       "      <td>&lt;p&gt;My chocolate chips cookies are always too c...</td>\n",
       "      <td>baking cookies texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How should I cook bacon in an oven?</td>\n",
       "      <td>&lt;p&gt;I've heard of people cooking bacon in an ov...</td>\n",
       "      <td>oven cooking-time bacon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the difference between white and brown...</td>\n",
       "      <td>&lt;p&gt;I always use brown extra large eggs, but I ...</td>\n",
       "      <td>eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the difference between baking soda and...</td>\n",
       "      <td>&lt;p&gt;And can I use one in place of the other in ...</td>\n",
       "      <td>substitutions please-remove-this-tag baking-so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>In a tomato sauce recipe, how can I cut the ac...</td>\n",
       "      <td>&lt;p&gt;It seems that every time I make a tomato sa...</td>\n",
       "      <td>sauce pasta tomatoes italian-cuisine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1        How can I get chewy chocolate chip cookies?   \n",
       "1   2                How should I cook bacon in an oven?   \n",
       "2   3  What is the difference between white and brown...   \n",
       "3   4  What is the difference between baking soda and...   \n",
       "4   5  In a tomato sauce recipe, how can I cut the ac...   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>My chocolate chips cookies are always too c...   \n",
       "1  <p>I've heard of people cooking bacon in an ov...   \n",
       "2  <p>I always use brown extra large eggs, but I ...   \n",
       "3  <p>And can I use one in place of the other in ...   \n",
       "4  <p>It seems that every time I make a tomato sa...   \n",
       "\n",
       "                                                tags  \n",
       "0                             baking cookies texture  \n",
       "1                            oven cooking-time bacon  \n",
       "2                                               eggs  \n",
       "3  substitutions please-remove-this-tag baking-so...  \n",
       "4               sauce pasta tomatoes italian-cuisine  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crytology: 10432 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>What are the benefits of the two permutation t...</td>\n",
       "      <td>&lt;p&gt;Why do we use a permutation table in the fi...</td>\n",
       "      <td>block-cipher des permutation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Why use a 1-2 Oblivious Transfer instead of a ...</td>\n",
       "      <td>&lt;p&gt;When initiating an &lt;a href=\"http://en.wikip...</td>\n",
       "      <td>oblivious-transfer multiparty-computation func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Why do we append the length of the message in ...</td>\n",
       "      <td>&lt;p&gt;As we know, &lt;a href=\"http://en.wikipedia.or...</td>\n",
       "      <td>sha-1 hash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>What is the general justification for the hard...</td>\n",
       "      <td>&lt;p&gt;Since most cryptographic hash functions are...</td>\n",
       "      <td>hash cryptanalysis preimage-resistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>How can I use asymmetric encryption, such as R...</td>\n",
       "      <td>&lt;p&gt;RSA is not designed to be used on long bloc...</td>\n",
       "      <td>encryption rsa public-key</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   3  What are the benefits of the two permutation t...   \n",
       "1   7  Why use a 1-2 Oblivious Transfer instead of a ...   \n",
       "2   8  Why do we append the length of the message in ...   \n",
       "3   9  What is the general justification for the hard...   \n",
       "4  14  How can I use asymmetric encryption, such as R...   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>Why do we use a permutation table in the fi...   \n",
       "1  <p>When initiating an <a href=\"http://en.wikip...   \n",
       "2  <p>As we know, <a href=\"http://en.wikipedia.or...   \n",
       "3  <p>Since most cryptographic hash functions are...   \n",
       "4  <p>RSA is not designed to be used on long bloc...   \n",
       "\n",
       "                                                tags  \n",
       "0                       block-cipher des permutation  \n",
       "1  oblivious-transfer multiparty-computation func...  \n",
       "2                                         sha-1 hash  \n",
       "3             hash cryptanalysis preimage-resistance  \n",
       "4                          encryption rsa public-key  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIY: 25918 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How do I install a new, non load bearing wall ...</td>\n",
       "      <td>&lt;p&gt;I'm looking to finish my basement and simpl...</td>\n",
       "      <td>remodeling basement carpentry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What kind of caulk should I use around my bath...</td>\n",
       "      <td>&lt;p&gt;I would like to recaulk between the bathtub...</td>\n",
       "      <td>caulking bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Is fiberglass mesh tape a good choice for dryw...</td>\n",
       "      <td>&lt;p&gt;I'm going to be doing some drywalling short...</td>\n",
       "      <td>drywall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Are there ways to determine if a wall is load ...</td>\n",
       "      <td>&lt;p&gt;Other than looking up blue prints, which ma...</td>\n",
       "      <td>walls load-bearing structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do I safely replace a worn out electrical ...</td>\n",
       "      <td>&lt;p&gt;I have a number of outlets that are old and...</td>\n",
       "      <td>repair electrical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  How do I install a new, non load bearing wall ...   \n",
       "1   2  What kind of caulk should I use around my bath...   \n",
       "2   3  Is fiberglass mesh tape a good choice for dryw...   \n",
       "3   4  Are there ways to determine if a wall is load ...   \n",
       "4   5  How do I safely replace a worn out electrical ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>I'm looking to finish my basement and simpl...   \n",
       "1  <p>I would like to recaulk between the bathtub...   \n",
       "2  <p>I'm going to be doing some drywalling short...   \n",
       "3  <p>Other than looking up blue prints, which ma...   \n",
       "4  <p>I have a number of outlets that are old and...   \n",
       "\n",
       "                            tags  \n",
       "0  remodeling basement carpentry  \n",
       "1              caulking bathroom  \n",
       "2                        drywall  \n",
       "3  walls load-bearing structural  \n",
       "4              repair electrical  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robotics: 2771 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the right approach to write the spin c...</td>\n",
       "      <td>&lt;p&gt;Imagine programming a 3 wheel soccer robot....</td>\n",
       "      <td>soccer control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I modify a low cost hobby servo to run...</td>\n",
       "      <td>&lt;p&gt;I've got some hobby servos (&lt;a href=\"http:/...</td>\n",
       "      <td>control rcservo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What useful gaits exist for a six legged robot...</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"http://www.oricomtech.com/projects...</td>\n",
       "      <td>gait walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Good Microcontrollers/SOCs for a Robotics Project</td>\n",
       "      <td>&lt;p&gt;I am looking for a starting point for my pr...</td>\n",
       "      <td>microcontroller arduino raspberry-pi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nearest-neighbor data structure for non-Euclid...</td>\n",
       "      <td>&lt;p&gt;I'm trying to implement a nearest-neighbor ...</td>\n",
       "      <td>motion-planning rrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is the right approach to write the spin c...   \n",
       "1   2  How can I modify a low cost hobby servo to run...   \n",
       "2   3  What useful gaits exist for a six legged robot...   \n",
       "3   4  Good Microcontrollers/SOCs for a Robotics Project   \n",
       "4   5  Nearest-neighbor data structure for non-Euclid...   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>Imagine programming a 3 wheel soccer robot....   \n",
       "1  <p>I've got some hobby servos (<a href=\"http:/...   \n",
       "2  <p><a href=\"http://www.oricomtech.com/projects...   \n",
       "3  <p>I am looking for a starting point for my pr...   \n",
       "4  <p>I'm trying to implement a nearest-neighbor ...   \n",
       "\n",
       "                                   tags  \n",
       "0                        soccer control  \n",
       "1                       control rcservo  \n",
       "2                             gait walk  \n",
       "3  microcontroller arduino raspberry-pi  \n",
       "4                   motion-planning rrt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel: 19279 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What are some Caribbean cruises for October?</td>\n",
       "      <td>&lt;p&gt;My fiancée and I are looking for a good Car...</td>\n",
       "      <td>caribbean cruising vacations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I find a guide that will take me safel...</td>\n",
       "      <td>&lt;p&gt;This was one of our definition questions, b...</td>\n",
       "      <td>guides extreme-tourism amazon-river amazon-jungle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Does Singapore Airlines offer any reward seats...</td>\n",
       "      <td>&lt;p&gt;Singapore Airlines has an all-business clas...</td>\n",
       "      <td>loyalty-programs routes ewr singapore-airlines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>What is the easiest transportation to use thro...</td>\n",
       "      <td>&lt;p&gt;Another definition question that interested...</td>\n",
       "      <td>romania transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>How can I visit Antarctica?</td>\n",
       "      <td>&lt;p&gt;A year ago I was reading some magazine, and...</td>\n",
       "      <td>extreme-tourism antarctica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1       What are some Caribbean cruises for October?   \n",
       "1   2  How can I find a guide that will take me safel...   \n",
       "2   4  Does Singapore Airlines offer any reward seats...   \n",
       "3   5  What is the easiest transportation to use thro...   \n",
       "4   6                        How can I visit Antarctica?   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>My fiancée and I are looking for a good Car...   \n",
       "1  <p>This was one of our definition questions, b...   \n",
       "2  <p>Singapore Airlines has an all-business clas...   \n",
       "3  <p>Another definition question that interested...   \n",
       "4  <p>A year ago I was reading some magazine, and...   \n",
       "\n",
       "                                                tags  \n",
       "0                       caribbean cruising vacations  \n",
       "1  guides extreme-tourism amazon-river amazon-jungle  \n",
       "2  loyalty-programs routes ewr singapore-airlines...  \n",
       "3                             romania transportation  \n",
       "4                         extreme-tourism antarctica  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 81926 questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is spin as it relates to subatomic partic...</td>\n",
       "      <td>&lt;p&gt;I often hear about subatomic particles havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What is your simplest explanation of the strin...</td>\n",
       "      <td>&lt;p&gt;How would you explain string theory to non ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lie theory, Representations and particle physics</td>\n",
       "      <td>&lt;p&gt;This is a question that has been posted at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Will Determinism be ever possible?</td>\n",
       "      <td>&lt;p&gt;What are the main problems that we need to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Hamilton's Principle</td>\n",
       "      <td>&lt;p&gt;Hamilton's principle states that a dynamic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is spin as it relates to subatomic partic...   \n",
       "1   2  What is your simplest explanation of the strin...   \n",
       "2   3   Lie theory, Representations and particle physics   \n",
       "3   7                 Will Determinism be ever possible?   \n",
       "4   9                               Hamilton's Principle   \n",
       "\n",
       "                                             content  \n",
       "0  <p>I often hear about subatomic particles havi...  \n",
       "1  <p>How would you explain string theory to non ...  \n",
       "2  <p>This is a question that has been posted at ...  \n",
       "3  <p>What are the main problems that we need to ...  \n",
       "4  <p>Hamilton's principle states that a dynamic ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pylab\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Convert csv files into dataframes\n",
    "biology_pd = pd.read_csv('DATA/biology.csv')\n",
    "cooking_pd = pd.read_csv('DATA/cooking.csv')\n",
    "cryptology_pd = pd.read_csv('DATA/crypto.csv')\n",
    "diy_pd = pd.read_csv('DATA/diy.csv')\n",
    "robotics_pd = pd.read_csv('DATA/robotics.csv')\n",
    "travel_pd = pd.read_csv('DATA/travel.csv')\n",
    "test_pd = pd.read_csv('DATA/test.csv')\n",
    "\n",
    "# Print dataframe heads\n",
    "print('Biology: %i questions' % biology_pd.shape[0])\n",
    "display(biology_pd.head())\n",
    "print('Cooking: %i questions' % cooking_pd.shape[0])\n",
    "display(cooking_pd.head())\n",
    "print('Crytology: %i questions' % cryptology_pd.shape[0])\n",
    "display(cryptology_pd.head())\n",
    "print('DIY: %i questions' % diy_pd.shape[0])\n",
    "display(diy_pd.head())\n",
    "print('Robotics: %i questions' % robotics_pd.shape[0])\n",
    "display(robotics_pd.head())\n",
    "print('Travel: %i questions' % travel_pd.shape[0])\n",
    "display(travel_pd.head())\n",
    "print('Test: %i questions' % test_pd.shape[0])\n",
    "display(test_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "9797677c-41ee-4ce7-d9b1-8887e12a0e07"
   },
   "outputs": [],
   "source": [
    "# Stop words from Stanford's NLP codebase: \n",
    "# github.com/stanfordnlp/CoreNLP/blob/master/data/edu/stanford/nlp/patterns/surface\n",
    "\n",
    "stop_words = [\"\", \" \", \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \n",
    "              \"and\",\"any\", \"are\", \"aren't\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \n",
    "              \"below\", \"between\", \"both\", \"but\", \"by\", \"can\", \"can't\",  \"cannot\", \"could\",\n",
    "              \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \n",
    "              \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\",  \"hadn't\",\"has\", \n",
    "              \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \n",
    "              \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \n",
    "              \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \n",
    "              \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \n",
    "              \"myself\", \"no\", \"nor\", \"not\" , \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\",\n",
    "              \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \n",
    "              \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \n",
    "              \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \n",
    "              \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \n",
    "              \"they've\", \"this\", \"those\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\",\n",
    "              \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \n",
    "              \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \n",
    "              \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\",\"you\", \n",
    "              \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \n",
    "              \"yourselves\", \"return\", \"arent\", \"cant\", \"couldnt\", \"didnt\", \"doesnt\", \"dont\", \n",
    "              \"hadnt\", \"hasnt\", \"havent\", \"hes\", \"heres\", \"hows\", \"im\", \"isnt\", \"its\", \"lets\",\n",
    "              \"mustnt\", \"shant\", \"shes\", \"shouldnt\", \"thats\", \"theres\", \"theyll\", \"theyre\", \n",
    "              \"theyve\", \"wasnt\", \"were\", \"werent\", \"whats\", \"whens\", \"wheres\", \"whos\", \"whys\",\n",
    "              \"wont\", \"wouldnt\", \"youd\", \"youll\", \"youre\", \"youve\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fe4d293f-0e7c-f102-9316-dcd6dcae93b3"
   },
   "source": [
    "Step 2: Preprocess Data\n",
    "--------------------------\n",
    "\n",
    "We need to convert the raw data into a format that our ML model can use during training and inference. We will accomplish this by parsing the HTML, then creating two NumPy arrays for each topic: data and labels (Test will only have data). The data array will be comprised of the words from the title and cleansed content, and the labels will be the words from the tags. Array elements will be words themselves, not characters or sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "e06ee3f6-fe71-4d82-bb15-eaae92dce8e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biology data: 796057 words\n",
      "['What', 'criticality', 'ribosome', 'binding', 'site', 'relative', 'start', 'codon', 'prokaryotic', 'translation', 'In', 'prokaryotic', 'translation', 'critical', 'efficient', 'translation', 'location', 'ribosome', 'binding', 'site', 'relative', 'start', 'codon', 'Ideally', 'supposed', '7b', 'away', 'start', 'How', '9', 'bases', 'away', 'even', 'Will', 'observable', 'effect', 'translation', 'How', 'RNAse', 'contamination', 'RNA', 'based', 'experiments', 'prevented', 'Does', 'anyone', 'suggestions', 'prevent', 'RNAse', 'contamination']\n",
      "\n",
      "Biology labels: 33129 words\n",
      "['ribosome', 'bindingsites', 'translation', 'syntheticbiology', 'rna', 'biochemistry', 'immunology', 'cellbiology', 'hematology', 'cellculture']\n",
      "\n",
      "Cooking data: 888022 words\n",
      "['How', 'I', 'get', 'chewy', 'chocolate', 'chip', 'cookies', 'My', 'chocolate', 'chips', 'cookies', 'always', 'crisp', 'How', 'I', 'get', 'chewy', 'cookies', 'like', 'Starbucks', 'Thank', 'everyone', 'answered', 'So', 'far', 'tip', 'biggest', 'impact', 'chill', 'rest', 'dough', 'however', 'I', 'also', 'increased', 'brown', 'sugar', 'ratio', 'increased', 'bit', 'butter', 'Also', 'adding', 'maple', 'syrup', 'helped', 'How', 'I', 'cook', 'bacon']\n",
      "\n",
      "Cooking labels: 35542 words\n",
      "['baking', 'cookies', 'texture', 'oven', 'cookingtime', 'bacon', 'eggs', 'substitutions', 'pleaseremovethistag', 'bakingsoda']\n",
      "\n",
      "Cryptology data: 918273 words\n",
      "['What', 'benefits', 'two', 'permutation', 'tables', 'DES', 'Why', 'use', 'permutation', 'table', 'first', 'step', 'DES', 'algorithm', 'one', 'end', 'algorithm', 'Why', 'use', '12', 'Oblivious', 'Transfer', 'instead', '1', 'n', 'Oblivious', 'Transfer', 'When', 'initiating', 'oblivious', 'transfer', 'someone', 'use', '12', 'oblivious', 'transfer', 'rather', 'going', '1', 'n', 'oblivious', 'transfer', 'Perhaps', 'slight', 'time', 'overhead', 'extra', 'message', 'encrypts', 'everything']\n",
      "\n",
      "Cryptology labels: 25484 words\n",
      "['blockcipher', 'des', 'permutation', 'oblivioustransfer', 'multipartycomputation', 'functionevaluation', 'sha1', 'hash', 'hash', 'cryptanalysis']\n",
      "\n",
      "Diy data: 1919825 words\n",
      "['How', 'I', 'install', 'new', 'non', 'load', 'bearing', 'wall', 'basement', 'Im', 'looking', 'finish', 'basement', 'simply', 'want', 'wall', 'concrete', 'blocks', 'make', 'wall', 'I', 'want', 'insulate', 'as', 'well', 'becomes', 'usable', 'family', 'room', 'Im', 'done', 'How', 'I', 'go', 'installing', 'wall', 'given', 'wooden', 'beams', 'ceiling', 'concrete', 'floor', 'What', 'kind', 'caulk', 'I', 'use', 'around', 'bathtub', 'I']\n",
      "\n",
      "Diy labels: 59129 words\n",
      "['remodeling', 'basement', 'carpentry', 'caulking', 'bathroom', 'drywall', 'walls', 'loadbearing', 'structural', 'repair']\n",
      "\n",
      "Robotics data: 267432 words\n",
      "['What', 'right', 'approach', 'write', 'spin', 'controller', 'soccer', 'robot', 'Imagine', 'programming', '3', 'wheel', 'soccer', 'robot', 'What', 'type', 'controller', 'use', 'spinning', 'P', 'PID', 'The', 'goal', 'controller', 'make', 'robot', 'stand', 'defined', 'angle', '0', 'degree', 'turn', 'back', 'rotated', 'hand', 'robot', 'I', 'use', 'stepper', 'motors', 'robot', 'servos', 'I', 'need', 'implement', 'software', 'I', 'written', 'sample', 'P']\n",
      "\n",
      "Robotics labels: 6517 words\n",
      "['soccer', 'control', 'control', 'rcservo', 'gait', 'walk', 'microcontroller', 'arduino', 'raspberrypi', 'motionplanning']\n",
      "\n",
      "Travel data: 1205987 words\n",
      "['What', 'Caribbean', 'cruises', 'October', 'My', 'fiancée', 'I', 'looking', 'good', 'Caribbean', 'cruise', 'October', 'wondering', 'islands', 'best', 'see', 'Cruise', 'line', 'take', 'It', 'seems', 'like', 'lot', 'cruises', 'run', 'month', 'due', 'Hurricane', 'season', 'Im', 'looking', 'good', 'options', 'EDIT', 'Well', 'travelling', '2012', 'How', 'I', 'find', 'guide', 'will', 'take', 'safely', 'through', 'Amazon', 'jungle', 'This', 'one', 'definition']\n",
      "\n",
      "Travel labels: 65332 words\n",
      "['caribbean', 'cruising', 'vacations', 'guides', 'extremetourism', 'amazonriver', 'amazonjungle', 'loyaltyprograms', 'routes', 'ewr']\n",
      "\n",
      "Test data: 6371600 words\n",
      "['What', 'spin', 'as', 'relates', 'subatomic', 'particles', 'I', 'often', 'hear', 'subatomic', 'particles', 'property', 'called', 'spin', 'also', 'actually', 'relate', 'spinning', 'axis', 'like', 'think', 'Which', 'particles', 'spin', 'What', 'spin', 'mean', 'actual', 'spinning', 'motion', 'What', 'simplest', 'explanation', 'string', 'theory', 'How', 'explain', 'string', 'theory', 'non', 'physicists', 'as', 'Im', 'specially', 'interested', 'plausible', 'needed', 'successfully', 'prove', 'Lie']\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframes to ndarrays\n",
    "biology_np = biology_pd[['title', 'content', 'tags']].to_numpy()  \n",
    "cooking_np = cooking_pd[['title', 'content', 'tags']].to_numpy()  \n",
    "cryptology_np = cryptology_pd[['title', 'content', 'tags']].to_numpy()  \n",
    "diy_np = diy_pd[['title', 'content', 'tags']].to_numpy()  \n",
    "robotics_np = robotics_pd[['title', 'content', 'tags']].to_numpy()  \n",
    "travel_np = travel_pd[['title', 'content', 'tags']].to_numpy()  \n",
    "test_np = test_pd[['title', 'content']].to_numpy()  \n",
    "\n",
    "\n",
    "# Parse html\n",
    "def parse_html(data_np):    \n",
    "    for i in range(data_np.shape[0]):\n",
    "        soup = BeautifulSoup(data_np[i,1], 'html.parser')\n",
    "        soup = soup.get_text()\n",
    "        soup = BeautifulSoup(soup, 'html.parser')\n",
    "        soup = soup.decode('utf8')\n",
    "        soup = soup.replace('\\n', ' ')\n",
    "        data_np[i,1] = soup\n",
    "\n",
    "parse_html(biology_np)\n",
    "parse_html(cooking_np)\n",
    "parse_html(cryptology_np)\n",
    "parse_html(diy_np)\n",
    "parse_html(robotics_np)\n",
    "parse_html(travel_np)\n",
    "parse_html(test_np)\n",
    "\n",
    "# Create datasets and labels\n",
    "def to_list(data):    \n",
    "    for i in range(len(data)):\n",
    "        data[i] = [''.join([ch for ch in s if ch.isalnum()]) for s in data[i].split(' ')]\n",
    "        #data[i] = [x for x in data[i] if len(x) > 0]\n",
    "    #return [x for xs in data for x in xs if len(x) > 0]\n",
    "    return [x for xs in data for x in xs if x not in stop_words]\n",
    "\n",
    "biology_x = to_list(biology_np[:,0] + ' ' + biology_np[:,1])\n",
    "biology_y = to_list(biology_np[:,2])\n",
    "cooking_x = to_list(cooking_np[:,0] + ' ' + cooking_np[:,1])\n",
    "cooking_y = to_list(cooking_np[:,2])\n",
    "cryptology_x = to_list(cryptology_np[:,0] + ' ' + cryptology_np[:,1])\n",
    "cryptology_y = to_list(cryptology_np[:,2])\n",
    "diy_x = to_list(diy_np[:,0] + ' ' + diy_np[:,1])\n",
    "diy_y = to_list(diy_np[:,2])\n",
    "robotics_x = to_list(robotics_np[:,0] + ' ' + robotics_np[:,1])\n",
    "robotics_y = to_list(robotics_np[:,2])\n",
    "travel_x = to_list(travel_np[:,0] + ' ' + travel_np[:,1])\n",
    "travel_y = to_list(travel_np[:,2])\n",
    "test_x = to_list(test_np[:,0] + ' ' + test_np[:,1])\n",
    "\n",
    "# Print sample data and labels\n",
    "print('Biology data: %i words' % len(biology_x))\n",
    "print(biology_x[:50])\n",
    "print('\\nBiology labels: %i words' % len(biology_y))\n",
    "print(biology_y[:10])\n",
    "print('\\nCooking data: %i words' % len(cooking_x))\n",
    "print(cooking_x[:50])\n",
    "print('\\nCooking labels: %i words' % len(cooking_y))\n",
    "print(cooking_y[:10])\n",
    "print('\\nCryptology data: %i words' % len(cryptology_x))\n",
    "print(cryptology_x[:50])\n",
    "print('\\nCryptology labels: %i words' % len(cryptology_y))\n",
    "print(cryptology_y[:10])\n",
    "print('\\nDiy data: %i words' % len(diy_x))\n",
    "print(diy_x[:50])\n",
    "print('\\nDiy labels: %i words' % len(diy_y))\n",
    "print(diy_y[:10])\n",
    "print('\\nRobotics data: %i words' % len(robotics_x))\n",
    "print(robotics_x[:50])\n",
    "print('\\nRobotics labels: %i words' % len(robotics_y))\n",
    "print(robotics_y[:10])\n",
    "print('\\nTravel data: %i words' % len(travel_x))\n",
    "print(travel_x[:50])\n",
    "print('\\nTravel labels: %i words' % len(travel_y))\n",
    "print(travel_y[:10])\n",
    "print('\\nTest data: %i words' % len(test_x))\n",
    "print(test_x[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e14746f2-b698-6131-c5cf-de02196faf93"
   },
   "source": [
    "Step 3: Embed Words\n",
    "-------------------\n",
    "\n",
    "Word embedding have shown to be extremely useful for practically all NLP tasks, as it converted words into dense vectors that are semantically meaningful, as opposed to a basic one-hot encoding method.\n",
    "Our implementation is based on the Skip-gram, explained in this TensorFlow [tutorial.](https://www.tensorflow.org/versions/r0.12/tutorials/word2vec/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "d5e69615-f513-9ef0-fe6e-49b764b97b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['What', 'spin', 'as', 'relates', 'subatomic', 'particles', 'I', 'often', 'hear', 'subatomic', 'particles', 'property', 'called', 'spin', 'also', 'actually', 'relate', 'spinning', 'axis', 'like']\n",
      "\n",
      "Target: ['as', 'as', 'as', 'as', 'relates', 'relates', 'relates', 'relates', 'subatomic', 'subatomic', 'subatomic', 'subatomic', 'particles', 'particles', 'particles', 'particles', 'I', 'I', 'I', 'I', 'often', 'often', 'often', 'often', 'hear', 'hear', 'hear', 'hear', 'subatomic', 'subatomic', 'subatomic', 'subatomic', 'particles', 'particles', 'particles', 'particles', 'property', 'property', 'property', 'property', 'called', 'called', 'called', 'called', 'spin', 'spin', 'spin', 'spin', 'also', 'also', 'also', 'also', 'actually', 'actually', 'actually', 'actually', 'relate', 'relate', 'relate', 'relate', 'spinning', 'spinning', 'spinning', 'spinning']\n",
      "\n",
      "Context: ['What', 'spin', 'relates', 'subatomic', 'spin', 'as', 'subatomic', 'particles', 'as', 'relates', 'particles', 'I', 'relates', 'subatomic', 'I', 'often', 'subatomic', 'particles', 'often', 'hear', 'particles', 'I', 'hear', 'subatomic', 'I', 'often', 'subatomic', 'particles', 'often', 'hear', 'particles', 'property', 'hear', 'subatomic', 'property', 'called', 'subatomic', 'particles', 'called', 'spin', 'particles', 'property', 'spin', 'also', 'property', 'called', 'also', 'actually', 'called', 'spin', 'actually', 'relate', 'spin', 'also', 'relate', 'spinning', 'also', 'actually', 'spinning', 'axis', 'actually', 'relate', 'axis', 'like']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "embedding_size = 64\n",
    "vocab_size = 10000\n",
    "num_sampled = 64\n",
    "num_context = 4\n",
    "data_index = 0\n",
    "\n",
    "def create_batch(data, data_index, num_context):\n",
    "    batch_targets = np.ndarray([batch_size], np.int32)\n",
    "    batch_contexts = np.ndarray([batch_size, 1], np.int32)\n",
    "    \n",
    "    for i in range(0, batch_size, num_context): \n",
    "        context_indexes = [x for x in range(data_index, data_index + num_context + 1)]\n",
    "        del context_indexes[len(context_indexes) // 2]\n",
    "        batch_targets[i:i + num_context] = data_index + num_context // 2\n",
    "        batch_contexts[i:i + num_context, 0] = context_indexes\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "\n",
    "    return batch_targets, batch_contexts\n",
    "\n",
    "test_batch_targets, test_batch_contexts = create_batch(robotics_x,\n",
    "                                                       data_index,\n",
    "                                                       num_context)\n",
    "\n",
    "print('Original: ' + str(test_x[:batch_size // num_context + num_context]) + '\\n')\n",
    "print('Target: ' + str([test_x[x] for x in test_batch_targets]) + '\\n')\n",
    "print('Context: ' + str([test_x[x[0]] for x in test_batch_contexts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "477db845-a970-32ee-6627-78031d53e3bd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 1 and 64 for '{{node nce_loss/MatMul}} = MatMul[T=DT_INT32, transpose_a=false, transpose_b=true](Placeholder_1, nce_loss/Slice_1)' with input shapes: [64,1], [64,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1653\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 1 and 64 for '{{node nce_loss/MatMul}} = MatMul[T=DT_INT32, transpose_a=false, transpose_b=true](Placeholder_1, nce_loss/Slice_1)' with input shapes: [64,1], [64,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-686dc763f95d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                          \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                                          \u001b[0mnum_sampled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                                          vocab_size))\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36mnce_loss\u001b[1;34m(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name)\u001b[0m\n\u001b[0;32m   2056\u001b[0m       \u001b[0mremove_accidental_hits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremove_accidental_hits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2057\u001b[0m       \u001b[0mpartition_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartition_strategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2058\u001b[1;33m       name=name)\n\u001b[0m\u001b[0;32m   2059\u001b[0m   sampled_losses = sigmoid_cross_entropy_with_logits(\n\u001b[0;32m   2060\u001b[0m       labels=labels, logits=logits, name=\"sampled_losses\")\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36m_compute_sampled_logits\u001b[1;34m(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed)\u001b[0m\n\u001b[0;32m   1776\u001b[0m     \u001b[1;31m# sampled_w has shape [num_sampled, dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m     \u001b[1;31m# Apply X*W', which yields [batch_size, num_sampled]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m     \u001b[0msampled_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;31m# Retrieve the true and sampled biases, compute the true logits, and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2982\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2983\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2984\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5585\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m   5586\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5587\u001b[1;33m                   name=name)\n\u001b[0m\u001b[0;32m   5588\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5589\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3327\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[1;32m-> 1817\u001b[1;33m                                 control_input_ops, op_def)\n\u001b[0m\u001b[0;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 1 and 64 for '{{node nce_loss/MatMul}} = MatMul[T=DT_INT32, transpose_a=false, transpose_b=true](Placeholder_1, nce_loss/Slice_1)' with input shapes: [64,1], [64,64]."
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    train_x = tf.placeholder(tf.int32, [batch_size])\n",
    "    train_y = tf.placeholder(tf.int32, [batch_size, 1])\n",
    "        \n",
    "    embedding_space = tf.Variable(tf.random_uniform([vocab_size, embedding_size]))\n",
    "    embedded_train_x = tf.nn.embedding_lookup(embedding_space, train_x)\n",
    "    weights = tf.Variable(tf.truncated_normal([vocab_size, embedding_size]))\n",
    "    biases = tf.Variable(tf.zeros([vocab_size]))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(weights, \n",
    "                                         biases, \n",
    "                                         embedded_train_x, \n",
    "                                         train_y, \n",
    "                                         num_sampled, \n",
    "                                         vocab_size))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)   \n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embedding_space), 1, keep_dims=True))\n",
    "    normalized_embedding_space = embedding_space / norm    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c80b7f34-8250-24c1-8ef6-5a9a6288e4a8"
   },
   "outputs": [],
   "source": [
    "num_steps = 10001\n",
    "data_index = 0\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()   \n",
    "\n",
    "    for step in range(num_steps):\n",
    "        batch_x, batch_y = create_batch(robotics_x, data_index, num_context) \n",
    "        _, l = session.run([optimizer, loss], {train_x:batch_x, train_y:batch_y})\n",
    "        \n",
    "        if step % 1000 == 0:            \n",
    "            print('Loss at step %i: %.2f' % (step, l))\n",
    "            \n",
    "    final_embedding_space = normalized_embedding_space.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "582b32ca-a0c9-feed-508b-e4793390bbae"
   },
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "tsne_embedding_space = tsne.fit_transform(final_embedding_space[:100])\n",
    "\n",
    "pylab.figure(figsize=(9, 9))\n",
    "\n",
    "for i in range(len(tsne_embedding_space)):\n",
    "    x, y = tsne_embedding_space[i, :]\n",
    "    pylab.scatter(x, y)\n",
    "    pylab.annotate(robotics_x[i], xy=(x, y))\n",
    "\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "\n",
    "stop_words = set(['a', \"a's\", 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', \"ain't\", 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', \"aren't\", 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'b', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'c', \"c'mon\", \"c's\", 'came', 'can', \"can't\", 'cannot', 'cant', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly', 'co', 'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering', 'contain', 'containing', 'contains', 'corresponding', 'could', \"couldn't\", 'course', 'currently', 'd', 'definitely', 'described', 'despite', 'did', \"didn't\", 'different', 'do', 'does', \"doesn't\", 'doing', \"don't\", 'done', 'down', 'downwards', 'during', 'e', 'each', 'edu', 'eg', 'eight', 'either', 'else', 'elsewhere', 'enough', 'entirely', 'especially', 'et', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'f', 'far', 'few', 'fifth', 'first', 'five', 'followed', 'following', 'follows', 'for', 'former', 'formerly', 'forth', 'four', 'from', 'further', 'furthermore', 'g', 'get', 'gets', 'getting', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'got', 'gotten', 'greetings', 'h', 'had', \"hadn't\", 'happens', 'hardly', 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he's\", 'hello', 'help', 'hence', 'her', 'here', \"here's\", 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him', 'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit', 'however', 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'ie', 'if', 'ignored', 'immediate', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'inner', 'insofar', 'instead', 'into', 'inward', 'is', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kept', 'know', 'knows', 'known', 'l', 'last', 'lately', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', \"let's\", 'like', 'liked', 'likely', 'little', 'look', 'looking', 'looks', 'ltd', 'm', 'mainly', 'many', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'merely', 'might', 'more', 'moreover', 'most', 'mostly', 'much', 'must', 'my', 'myself', 'n', 'name', 'namely', 'nd', 'near', 'nearly', 'necessary', 'need', 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'p', 'particular', 'particularly', 'per', 'perhaps', 'placed', 'please', 'plus', 'possible', 'presumably', 'probably', 'provides', 'q', 'que', 'quite', 'qv', 'r', 'rather', 'rd', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'relatively', 'respectively', 'right', 's', 'said', 'same', 'saw', 'say', 'saying', 'says', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'she', 'should', \"shouldn't\", 'since', 'six', 'so', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry', 'specified', 'specify', 'specifying', 'still', 'sub', 'such', 'sup', 'sure', 't', \"t's\", 'take', 'taken', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', \"that's\", 'thats', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', \"there's\", 'thereafter', 'thereby', 'therefore', 'therein', 'theres', 'thereupon', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'think', 'third', 'this', 'thorough', 'thoroughly', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'twice', 'two', 'u', 'un', 'under', 'unfortunately', 'unless', 'unlikely', 'until', 'unto', 'up', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'using', 'usually', 'uucp', 'v', 'value', 'various', 'very', 'via', 'viz', 'vs', 'w', 'want', 'wants', 'was', \"wasn't\", 'way', 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'welcome', 'well', 'went', 'were', \"weren't\", 'what', \"what's\", 'whatever', 'when', 'whence', 'whenever', 'where', \"where's\", 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', \"who's\", 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'willing', 'wish', 'with', 'within', 'without', \"won't\", 'wonder', 'would', 'would', \"wouldn't\", 'x', 'y', 'yes', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', 'z', 'zero', ''])\n",
    "def f1_score(tp, fp, fn):\n",
    "    p = (tp*1.) / (tp+fp)\n",
    "    r = (tp*1.) / (tp+fn)\n",
    "    f1 = (2*p*r)/(p+r)\n",
    "    return f1\n",
    "\n",
    "def clean_html(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def get_words(text):\n",
    "    word_split = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n",
    "    return [word.strip().lower() for word in word_split.split(text)]\n",
    "\n",
    "data_path = \"../input/\"\n",
    "in_file = open(data_path+\"test.csv\")\n",
    "out_file = open(\"sub_freq.csv\", \"w\")\n",
    "reader = csv.DictReader(in_file)\n",
    "writer = csv.writer(out_file)\n",
    "writer.writerow(['id','tags'])\n",
    "for ind, row in enumerate(reader):\n",
    "    text = clean_html(row[\"title\"])\n",
    "    tfrequency_dict = defaultdict(int)\n",
    "    word_count = 0.\n",
    "    for word in get_words(text):\n",
    "        if word not in stop_words and word.isalpha():\n",
    "            tfrequency_dict[word] += 1\n",
    "\t\t\tword_count += 1.\n",
    "\tfor word in tfrequency_dict:\n",
    "\t\ttf = tfrequency_dict[word] / word_count\n",
    "\t\ttfrequency_dict[word] = tf \n",
    "\tpred_title_tags = sorted(tfrequency_dict, key=tfrequency_dict.get, reverse=True)[:10]\n",
    "\n",
    "\ttext = clean_html(row[\"content\"])\n",
    "\tdfrequency_dict = defaultdict(int)\n",
    "\tword_count = 0.\n",
    "\tfor word in get_words(text):\n",
    "\t\tif word not in stop_words and word.isalpha():\n",
    "\t\t\tdfrequency_dict[word] += 1\n",
    "\t\t\tword_count += 1.\n",
    "\tfor word in dfrequency_dict:\n",
    "\t\ttf = dfrequency_dict[word] / word_count\n",
    "\t\tdfrequency_dict[word] = tf \n",
    "\tpred_content_tags = sorted(dfrequency_dict, key=dfrequency_dict.get, reverse=True)[:10]\n",
    "\n",
    "\tpred_tags_dict = {}\n",
    "\tfor word in set(pred_title_tags + pred_content_tags):\n",
    "\t\tpred_tags_dict[word] = tfrequency_dict.get(word,0) + dfrequency_dict.get(word,0)\n",
    "\tpred_tags = set(sorted(pred_tags_dict, key=pred_tags_dict.get, reverse=True)[:3])\n",
    "\t\n",
    "\twriter.writerow([row['id'], \" \".join(pred_tags)])\n",
    "\tif ind%50000 == 0:\n",
    "\t\tprint(\"Processed : \", ind)\n",
    "\n",
    "\n",
    "in_file.close()\n",
    "out_file.close()"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
